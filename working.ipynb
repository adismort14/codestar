{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\python311\\lib\\site-packages (0.0.334)\n",
      "Requirement already satisfied: chromadb in c:\\python311\\lib\\site-packages (0.4.17)\n",
      "Requirement already satisfied: pypdf in c:\\python311\\lib\\site-packages (3.17.1)\n",
      "Requirement already satisfied: sentence_transformers in c:\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: InstructorEmbedding in c:\\python311\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: streamlit in c:\\python311\\lib\\site-packages (1.29.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\python311\\lib\\site-packages (0.41.3.post2)\n",
      "Requirement already satisfied: ctransformers[cuda] in c:\\python311\\lib\\site-packages (0.2.27)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python311\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python311\\lib\\site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python311\\lib\\site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\python311\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python311\\lib\\site-packages (from langchain) (0.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python311\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.62 in c:\\python311\\lib\\site-packages (from langchain) (0.0.63)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python311\\lib\\site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python311\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\python311\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\python311\\lib\\site-packages (from chromadb) (0.104.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\python311\\lib\\site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python311\\lib\\site-packages (from chromadb) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\python311\\lib\\site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\python311\\lib\\site-packages (from chromadb) (1.16.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\python311\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\python311\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\python311\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\python311\\lib\\site-packages (from chromadb) (0.14.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\python311\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\python311\\lib\\site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\python311\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\python311\\lib\\site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\python311\\lib\\site-packages (from chromadb) (1.59.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\python311\\lib\\site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\python311\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\python311\\lib\\site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\python311\\lib\\site-packages (from sentence_transformers) (4.35.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\python311\\lib\\site-packages (from sentence_transformers) (2.1.2+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\python311\\lib\\site-packages (from sentence_transformers) (0.16.2+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from sentence_transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\python311\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\python311\\lib\\site-packages (from sentence_transformers) (0.17.3)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\python311\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\python311\\lib\\site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\python311\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\python311\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\python311\\lib\\site-packages (from streamlit) (10.0.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\python311\\lib\\site-packages (from streamlit) (4.24.4)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\python311\\lib\\site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\python311\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\python311\\lib\\site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\python311\\lib\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\python311\\lib\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\python311\\lib\\site-packages (from streamlit) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\python311\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\python311\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\python311\\lib\\site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in c:\\python311\\lib\\site-packages (from ctransformers[cuda]) (9.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in c:\\python311\\lib\\site-packages (from ctransformers[cuda]) (12.3.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in c:\\python311\\lib\\site-packages (from ctransformers[cuda]) (12.3.101)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\n",
      "Requirement already satisfied: toolz in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python311\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python311\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\python311\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.12.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.23.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.6.1)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in c:\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: coloredlogs in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in c:\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in c:\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in c:\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in c:\\python311\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\python311\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\python311\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\python311\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain chromadb pypdf sentence_transformers InstructorEmbedding streamlit bitsandbytes ctransformers[cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Python311\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:06:29.858544Z",
     "iopub.status.busy": "2024-01-02T14:06:29.858168Z",
     "iopub.status.idle": "2024-01-02T14:06:50.360634Z",
     "shell.execute_reply": "2024-01-02T14:06:50.359661Z",
     "shell.execute_reply.started": "2024-01-02T14:06:29.858515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# New Backend Imports\n",
    "\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old backend imports\n",
    "\n",
    "import git\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:06:55.442029Z",
     "iopub.status.busy": "2024-01-02T14:06:55.440800Z",
     "iopub.status.idle": "2024-01-02T14:07:13.261609Z",
     "shell.execute_reply": "2024-01-02T14:07:13.260814Z",
     "shell.execute_reply.started": "2024-01-02T14:06:55.441994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 98.26it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 317.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "\n",
    "config = {'max_new_tokens': 2048, 'temperature': 0.1, 'context_length': 2048}\n",
    "llm = CTransformers(model='TheBloke/Mistral-7B-Instruct-v0.1-GGUF',model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", config=config, n_ctx=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:10:58.437819Z",
     "iopub.status.busy": "2024-01-02T14:10:58.437018Z",
     "iopub.status.idle": "2024-01-02T14:10:58.499271Z",
     "shell.execute_reply": "2024-01-02T14:10:58.498595Z",
     "shell.execute_reply.started": "2024-01-02T14:10:58.437787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "\n",
    "loader=PyPDFLoader('data/Resume_balanced.pdf')\n",
    "# loader = DirectoryLoader('data', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:11:06.120837Z",
     "iopub.status.busy": "2024-01-02T14:11:06.120172Z",
     "iopub.status.idle": "2024-01-02T14:11:06.125800Z",
     "shell.execute_reply": "2024-01-02T14:11:06.124781Z",
     "shell.execute_reply.started": "2024-01-02T14:11:06.120803Z"
    }
   },
   "outputs": [],
   "source": [
    "# #splitting the text into\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=300)\n",
    "# texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:11:17.644706Z",
     "iopub.status.busy": "2024-01-02T14:11:17.643981Z",
     "iopub.status.idle": "2024-01-02T14:11:17.650919Z",
     "shell.execute_reply": "2024-01-02T14:11:17.650103Z",
     "shell.execute_reply.started": "2024-01-02T14:11:17.644672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:11:29.038480Z",
     "iopub.status.busy": "2024-01-02T14:11:29.037642Z",
     "iopub.status.idle": "2024-01-02T14:11:38.113106Z",
     "shell.execute_reply": "2024-01-02T14:11:38.112172Z",
     "shell.execute_reply.started": "2024-01-02T14:11:29.038436Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<?, ?B/s]\n",
      "Downloading 1_Pooling/config.json: 100%|██████████| 270/270 [00:00<00:00, 179kB/s]\n",
      "Downloading 2_Dense/config.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 3.15M/3.15M [00:01<00:00, 2.45MB/s]\n",
      "Downloading README.md: 100%|██████████| 66.3k/66.3k [00:00<00:00, 397kB/s]\n",
      "Downloading config.json: 100%|██████████| 1.53k/1.53k [00:00<?, ?B/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [01:05<00:00, 20.4MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 2.19MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 24.8MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 2.42M/2.42M [00:01<00:00, 2.17MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 2.41k/2.41k [00:00<?, ?B/s]\n",
      "Downloading modules.json: 100%|██████████| 461/461 [00:00<00:00, 459kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\",\n",
    "#                                                       model_kwargs={'device': 'cuda:0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:11:41.343779Z",
     "iopub.status.busy": "2024-01-02T14:11:41.342893Z",
     "iopub.status.idle": "2024-01-02T14:11:48.333233Z",
     "shell.execute_reply": "2024-01-02T14:11:48.332451Z",
     "shell.execute_reply.started": "2024-01-02T14:11:41.343736Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m embedding \u001b[38;5;241m=\u001b[39m instructor_embeddings\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# vectordb = Chroma.from_documents(documents=texts,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#                                  embedding=embedding,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#                                  persist_directory=persist_directory)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# persiste the db to disk\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# vectordb.persist()\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# vectordb = None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:771\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    770\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:729\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    724\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    725\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    726\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    727\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    728\u001b[0m     ):\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\embeddings\\huggingface.py:171\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace instruct model.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction, text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m--> 171\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:521\u001b[0m, in \u001b[0;36mINSTRUCTOR.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_device\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentences[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# # Embed and store the texts\n",
    "# # Supplying a persist_directory will store the embeddings on disk\n",
    "# persist_directory = 'db'\n",
    "\n",
    "# ## Here is the nmew embeddings being used\n",
    "# embedding = instructor_embeddings\n",
    "\n",
    "# # vectordb = Chroma.from_documents(documents=texts,\n",
    "# #                                  embedding=embedding,\n",
    "# #                                  persist_directory=persist_directory)\n",
    "\n",
    "# vectordb = Chroma.from_documents(documents=texts,\n",
    "#                                  embedding=embedding,)\n",
    "\n",
    "# # persiste the db to disk\n",
    "# # vectordb.persist()\n",
    "# # vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:11:53.797583Z",
     "iopub.status.busy": "2024-01-02T14:11:53.796912Z",
     "iopub.status.idle": "2024-01-02T14:11:53.801947Z",
     "shell.execute_reply": "2024-01-02T14:11:53.801056Z",
     "shell.execute_reply.started": "2024-01-02T14:11:53.797547Z"
    }
   },
   "outputs": [],
   "source": [
    "# retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:12:00.935393Z",
     "iopub.status.busy": "2024-01-02T14:12:00.934347Z",
     "iopub.status.idle": "2024-01-02T14:12:00.942259Z",
     "shell.execute_reply": "2024-01-02T14:12:00.941244Z",
     "shell.execute_reply.started": "2024-01-02T14:12:00.935341Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "# qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "#                                   chain_type=\"stuff\",\n",
    "#                                   retriever=retriever,\n",
    "#                                   return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:12:08.564038Z",
     "iopub.status.busy": "2024-01-02T14:12:08.563154Z",
     "iopub.status.idle": "2024-01-02T14:12:08.570347Z",
     "shell.execute_reply": "2024-01-02T14:12:08.569448Z",
     "shell.execute_reply.started": "2024-01-02T14:12:08.563987Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Cite sources\n",
    "\n",
    "# import textwrap\n",
    "\n",
    "# def wrap_text_preserve_newlines(text, width=110):\n",
    "#     # Split the input text into lines based on newline characters\n",
    "#     lines = text.split('\\n')\n",
    "\n",
    "#     # Wrap each line individually\n",
    "#     wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "#     # Join the wrapped lines back together using newline characters\n",
    "#     wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "#     return wrapped_text\n",
    "\n",
    "# def process_llm_response(llm_response):\n",
    "#     print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "#     print('\\n\\nSources:')\n",
    "#     for source in llm_response[\"source_documents\"]:\n",
    "#         print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGitLink(git_link) -> None:\n",
    "    last_name = git_link.split(\"/\")[-1]\n",
    "    clone_path = last_name.split(\".\")[0]\n",
    "    return clone_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repo(git_link, clone_path):\n",
    "    if not os.path.exists(clone_path):\n",
    "        git.Repo.clone_from(git_link, clone_path)\n",
    "        return\n",
    "\n",
    "\n",
    "def extract_all_files(clone_path, docs, allowed_extensions):\n",
    "    root_dir = clone_path\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            file_extension = os.path.splitext(file)[1]\n",
    "            if file_extension in allowed_extensions:\n",
    "                try:\n",
    "                    loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "                    docs.extend(loader.load_and_split())\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_files(docs):\n",
    "    # text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    # texts = text_splitter.split_documents(docs)\n",
    "    #splitting the text into\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts\n",
    "\n",
    "\n",
    "# def embed_deeplake(texts, deeplake_path, hf):\n",
    "#     db = DeepLake(dataset_path=deeplake_path, embedding_function=hf, overwrite=True)\n",
    "#     db.add_documents(texts)\n",
    "#     return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=chunk_files(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectordb(texts):\n",
    "    # db = DeepLake(dataset_path=deeplake_path, embedding_function=hf, overwrite=True)\n",
    "    # db.add_documents(texts)\n",
    "    # return db\n",
    "\n",
    "    instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\",\n",
    "                                                      model_kwargs={'device': 'cuda:0'})\n",
    "    # Embed and store the texts\n",
    "    # Supplying a persist_directory will store the embeddings on disk\n",
    "    # persist_directory = 'db'\n",
    "\n",
    "    ## Here is the nmew embeddings being used\n",
    "    embedding = instructor_embeddings\n",
    "\n",
    "    # vectordb = Chroma.from_documents(documents=texts,\n",
    "    #                                  embedding=embedding,\n",
    "    #                                  persist_directory=persist_directory)\n",
    "\n",
    "    vectordb = Chroma.from_documents(documents=texts,\n",
    "                                    embedding=embedding,)\n",
    "    \n",
    "    return vectordb\n",
    "\n",
    "    # persiste the db to disk\n",
    "    # vectordb.persist()\n",
    "    # vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "vectordb=create_vectordb(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:12:16.966073Z",
     "iopub.status.busy": "2024-01-02T14:12:16.965734Z",
     "iopub.status.idle": "2024-01-02T14:17:17.005832Z",
     "shell.execute_reply": "2024-01-02T14:17:17.004840Z",
     "shell.execute_reply.started": "2024-01-02T14:12:16.966048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (1025) exceeded maximum context length (1024).\n",
      "Number of tokens (1026) exceeded maximum context length (1024).\n",
      "Number of tokens (1027) exceeded maximum context length (1024).\n",
      "Number of tokens (1028) exceeded maximum context length (1024).\n",
      "Number of tokens (1029) exceeded maximum context length (1024).\n",
      "Number of tokens (1030) exceeded maximum context length (1024).\n",
      "Number of tokens (1031) exceeded maximum context length (1024).\n",
      "Number of tokens (1032) exceeded maximum context length (1024).\n",
      "Number of tokens (1033) exceeded maximum context length (1024).\n",
      "Number of tokens (1034) exceeded maximum context length (1024).\n",
      "Number of tokens (1035) exceeded maximum context length (1024).\n",
      "Number of tokens (1036) exceeded maximum context length (1024).\n",
      "Number of tokens (1037) exceeded maximum context length (1024).\n",
      "Number of tokens (1038) exceeded maximum context length (1024).\n",
      "Number of tokens (1039) exceeded maximum context length (1024).\n",
      "Number of tokens (1040) exceeded maximum context length (1024).\n",
      "Number of tokens (1041) exceeded maximum context length (1024).\n",
      "Number of tokens (1042) exceeded maximum context length (1024).\n",
      "Number of tokens (1043) exceeded maximum context length (1024).\n",
      "Number of tokens (1044) exceeded maximum context length (1024).\n",
      "Number of tokens (1045) exceeded maximum context length (1024).\n",
      "Number of tokens (1046) exceeded maximum context length (1024).\n",
      "Number of tokens (1047) exceeded maximum context length (1024).\n",
      "Number of tokens (1048) exceeded maximum context length (1024).\n",
      "Number of tokens (1049) exceeded maximum context length (1024).\n",
      "Number of tokens (1050) exceeded maximum context length (1024).\n",
      "Number of tokens (1051) exceeded maximum context length (1024).\n",
      "Number of tokens (1052) exceeded maximum context length (1024).\n",
      "Number of tokens (1053) exceeded maximum context length (1024).\n",
      "Number of tokens (1054) exceeded maximum context length (1024).\n",
      "Number of tokens (1055) exceeded maximum context length (1024).\n",
      "Number of tokens (1056) exceeded maximum context length (1024).\n",
      "Number of tokens (1057) exceeded maximum context length (1024).\n",
      "Number of tokens (1058) exceeded maximum context length (1024).\n",
      "Number of tokens (1059) exceeded maximum context length (1024).\n",
      "Number of tokens (1060) exceeded maximum context length (1024).\n",
      "Number of tokens (1061) exceeded maximum context length (1024).\n",
      "Number of tokens (1062) exceeded maximum context length (1024).\n",
      "Number of tokens (1063) exceeded maximum context length (1024).\n",
      "Number of tokens (1064) exceeded maximum context length (1024).\n",
      "Number of tokens (1065) exceeded maximum context length (1024).\n",
      "Number of tokens (1066) exceeded maximum context length (1024).\n",
      "Number of tokens (1067) exceeded maximum context length (1024).\n",
      "Number of tokens (1068) exceeded maximum context length (1024).\n",
      "Number of tokens (1069) exceeded maximum context length (1024).\n",
      "Number of tokens (1070) exceeded maximum context length (1024).\n",
      "Number of tokens (1071) exceeded maximum context length (1024).\n",
      "Number of tokens (1072) exceeded maximum context length (1024).\n",
      "Number of tokens (1073) exceeded maximum context length (1024).\n",
      "Number of tokens (1074) exceeded maximum context length (1024).\n",
      "Number of tokens (1075) exceeded maximum context length (1024).\n",
      "Number of tokens (1076) exceeded maximum context length (1024).\n",
      "Number of tokens (1077) exceeded maximum context length (1024).\n",
      "Number of tokens (1078) exceeded maximum context length (1024).\n",
      "Number of tokens (1079) exceeded maximum context length (1024).\n",
      "Number of tokens (1080) exceeded maximum context length (1024).\n",
      "Number of tokens (1081) exceeded maximum context length (1024).\n",
      "Number of tokens (1082) exceeded maximum context length (1024).\n",
      "Number of tokens (1083) exceeded maximum context length (1024).\n",
      "Number of tokens (1084) exceeded maximum context length (1024).\n",
      "Number of tokens (1085) exceeded maximum context length (1024).\n",
      "Number of tokens (1086) exceeded maximum context length (1024).\n",
      "Number of tokens (1087) exceeded maximum context length (1024).\n",
      "Number of tokens (1088) exceeded maximum context length (1024).\n",
      "Number of tokens (1089) exceeded maximum context length (1024).\n",
      "Number of tokens (1090) exceeded maximum context length (1024).\n",
      "Number of tokens (1091) exceeded maximum context length (1024).\n",
      "Number of tokens (1092) exceeded maximum context length (1024).\n",
      "Number of tokens (1093) exceeded maximum context length (1024).\n",
      "Number of tokens (1094) exceeded maximum context length (1024).\n",
      "Number of tokens (1095) exceeded maximum context length (1024).\n",
      "Number of tokens (1096) exceeded maximum context length (1024).\n",
      "Number of tokens (1097) exceeded maximum context length (1024).\n",
      "Number of tokens (1098) exceeded maximum context length (1024).\n",
      "Number of tokens (1099) exceeded maximum context length (1024).\n",
      "Number of tokens (1100) exceeded maximum context length (1024).\n",
      "Number of tokens (1101) exceeded maximum context length (1024).\n",
      "Number of tokens (1102) exceeded maximum context length (1024).\n",
      "Number of tokens (1103) exceeded maximum context length (1024).\n",
      "Number of tokens (1104) exceeded maximum context length (1024).\n",
      "Number of tokens (1105) exceeded maximum context length (1024).\n",
      "Number of tokens (1106) exceeded maximum context length (1024).\n",
      "Number of tokens (1107) exceeded maximum context length (1024).\n",
      "Number of tokens (1108) exceeded maximum context length (1024).\n",
      "Number of tokens (1109) exceeded maximum context length (1024).\n",
      "Number of tokens (1110) exceeded maximum context length (1024).\n",
      "Number of tokens (1111) exceeded maximum context length (1024).\n",
      "Number of tokens (1112) exceeded maximum context length (1024).\n",
      "Number of tokens (1113) exceeded maximum context length (1024).\n",
      "Number of tokens (1114) exceeded maximum context length (1024).\n",
      "Number of tokens (1115) exceeded maximum context length (1024).\n",
      "Number of tokens (1116) exceeded maximum context length (1024).\n",
      "Number of tokens (1117) exceeded maximum context length (1024).\n",
      "Number of tokens (1118) exceeded maximum context length (1024).\n",
      "Number of tokens (1119) exceeded maximum context length (1024).\n",
      "Number of tokens (1120) exceeded maximum context length (1024).\n",
      "Number of tokens (1121) exceeded maximum context length (1024).\n",
      "Number of tokens (1122) exceeded maximum context length (1024).\n",
      "Number of tokens (1123) exceeded maximum context length (1024).\n",
      "Number of tokens (1124) exceeded maximum context length (1024).\n",
      "Number of tokens (1125) exceeded maximum context length (1024).\n",
      "Number of tokens (1126) exceeded maximum context length (1024).\n",
      "Number of tokens (1127) exceeded maximum context length (1024).\n",
      "Number of tokens (1128) exceeded maximum context length (1024).\n",
      "Number of tokens (1129) exceeded maximum context length (1024).\n",
      "Number of tokens (1130) exceeded maximum context length (1024).\n",
      "Number of tokens (1131) exceeded maximum context length (1024).\n",
      "Number of tokens (1132) exceeded maximum context length (1024).\n",
      "Number of tokens (1133) exceeded maximum context length (1024).\n",
      "Number of tokens (1134) exceeded maximum context length (1024).\n",
      "Number of tokens (1135) exceeded maximum context length (1024).\n",
      "Number of tokens (1136) exceeded maximum context length (1024).\n",
      "Number of tokens (1137) exceeded maximum context length (1024).\n",
      "Number of tokens (1138) exceeded maximum context length (1024).\n",
      "Number of tokens (1139) exceeded maximum context length (1024).\n",
      "Number of tokens (1140) exceeded maximum context length (1024).\n",
      "Number of tokens (1141) exceeded maximum context length (1024).\n",
      "Number of tokens (1142) exceeded maximum context length (1024).\n",
      "Number of tokens (1143) exceeded maximum context length (1024).\n",
      "Number of tokens (1144) exceeded maximum context length (1024).\n",
      "Number of tokens (1145) exceeded maximum context length (1024).\n",
      "Number of tokens (1146) exceeded maximum context length (1024).\n",
      "Number of tokens (1147) exceeded maximum context length (1024).\n",
      "Number of tokens (1148) exceeded maximum context length (1024).\n",
      "Number of tokens (1149) exceeded maximum context length (1024).\n",
      "Number of tokens (1150) exceeded maximum context length (1024).\n",
      "Number of tokens (1151) exceeded maximum context length (1024).\n",
      "Number of tokens (1152) exceeded maximum context length (1024).\n",
      "Number of tokens (1153) exceeded maximum context length (1024).\n",
      "Number of tokens (1154) exceeded maximum context length (1024).\n",
      "Number of tokens (1155) exceeded maximum context length (1024).\n",
      "Number of tokens (1156) exceeded maximum context length (1024).\n",
      "Number of tokens (1157) exceeded maximum context length (1024).\n",
      "Number of tokens (1158) exceeded maximum context length (1024).\n",
      "Number of tokens (1159) exceeded maximum context length (1024).\n",
      "Number of tokens (1160) exceeded maximum context length (1024).\n",
      "Number of tokens (1161) exceeded maximum context length (1024).\n",
      "Number of tokens (1162) exceeded maximum context length (1024).\n",
      "Number of tokens (1163) exceeded maximum context length (1024).\n",
      "Number of tokens (1164) exceeded maximum context length (1024).\n",
      "Number of tokens (1165) exceeded maximum context length (1024).\n",
      "Number of tokens (1166) exceeded maximum context length (1024).\n",
      "Number of tokens (1167) exceeded maximum context length (1024).\n",
      "Number of tokens (1168) exceeded maximum context length (1024).\n",
      "Number of tokens (1169) exceeded maximum context length (1024).\n",
      "Number of tokens (1170) exceeded maximum context length (1024).\n",
      "Number of tokens (1171) exceeded maximum context length (1024).\n",
      "Number of tokens (1172) exceeded maximum context length (1024).\n",
      "Number of tokens (1173) exceeded maximum context length (1024).\n",
      "Number of tokens (1174) exceeded maximum context length (1024).\n",
      "Number of tokens (1175) exceeded maximum context length (1024).\n",
      "Number of tokens (1176) exceeded maximum context length (1024).\n",
      "Number of tokens (1177) exceeded maximum context length (1024).\n",
      "Number of tokens (1178) exceeded maximum context length (1024).\n",
      "Number of tokens (1179) exceeded maximum context length (1024).\n",
      "Number of tokens (1180) exceeded maximum context length (1024).\n",
      "Number of tokens (1181) exceeded maximum context length (1024).\n",
      "Number of tokens (1182) exceeded maximum context length (1024).\n",
      "Number of tokens (1183) exceeded maximum context length (1024).\n",
      "Number of tokens (1184) exceeded maximum context length (1024).\n",
      "Number of tokens (1185) exceeded maximum context length (1024).\n",
      "Number of tokens (1186) exceeded maximum context length (1024).\n",
      "Number of tokens (1187) exceeded maximum context length (1024).\n",
      "Number of tokens (1188) exceeded maximum context length (1024).\n",
      "Number of tokens (1189) exceeded maximum context length (1024).\n",
      "Number of tokens (1190) exceeded maximum context length (1024).\n",
      "Number of tokens (1191) exceeded maximum context length (1024).\n",
      "Number of tokens (1192) exceeded maximum context length (1024).\n",
      "Number of tokens (1193) exceeded maximum context length (1024).\n",
      "Number of tokens (1194) exceeded maximum context length (1024).\n",
      "Number of tokens (1195) exceeded maximum context length (1024).\n",
      "Number of tokens (1196) exceeded maximum context length (1024).\n",
      "Number of tokens (1197) exceeded maximum context length (1024).\n",
      "Number of tokens (1198) exceeded maximum context length (1024).\n",
      "Number of tokens (1199) exceeded maximum context length (1024).\n",
      "Number of tokens (1200) exceeded maximum context length (1024).\n",
      "Number of tokens (1201) exceeded maximum context length (1024).\n",
      "Number of tokens (1202) exceeded maximum context length (1024).\n",
      "Number of tokens (1203) exceeded maximum context length (1024).\n",
      "Number of tokens (1204) exceeded maximum context length (1024).\n",
      "Number of tokens (1205) exceeded maximum context length (1024).\n",
      "Number of tokens (1206) exceeded maximum context length (1024).\n",
      "Number of tokens (1207) exceeded maximum context length (1024).\n",
      "Number of tokens (1208) exceeded maximum context length (1024).\n",
      "Number of tokens (1209) exceeded maximum context length (1024).\n",
      "Number of tokens (1210) exceeded maximum context length (1024).\n",
      "Number of tokens (1211) exceeded maximum context length (1024).\n",
      "Number of tokens (1212) exceeded maximum context length (1024).\n",
      "Number of tokens (1213) exceeded maximum context length (1024).\n",
      "Number of tokens (1214) exceeded maximum context length (1024).\n",
      "Number of tokens (1215) exceeded maximum context length (1024).\n",
      "Number of tokens (1216) exceeded maximum context length (1024).\n",
      "Number of tokens (1217) exceeded maximum context length (1024).\n",
      "Number of tokens (1218) exceeded maximum context length (1024).\n",
      "Number of tokens (1219) exceeded maximum context length (1024).\n",
      "Number of tokens (1220) exceeded maximum context length (1024).\n",
      "Number of tokens (1221) exceeded maximum context length (1024).\n",
      "Number of tokens (1222) exceeded maximum context length (1024).\n",
      "Number of tokens (1223) exceeded maximum context length (1024).\n",
      "Number of tokens (1224) exceeded maximum context length (1024).\n",
      "Number of tokens (1225) exceeded maximum context length (1024).\n",
      "Number of tokens (1226) exceeded maximum context length (1024).\n",
      "Number of tokens (1227) exceeded maximum context length (1024).\n",
      "Number of tokens (1228) exceeded maximum context length (1024).\n",
      "Number of tokens (1229) exceeded maximum context length (1024).\n",
      "Number of tokens (1230) exceeded maximum context length (1024).\n",
      "Number of tokens (1231) exceeded maximum context length (1024).\n",
      "Number of tokens (1232) exceeded maximum context length (1024).\n",
      "Number of tokens (1233) exceeded maximum context length (1024).\n",
      "Number of tokens (1234) exceeded maximum context length (1024).\n",
      "Number of tokens (1235) exceeded maximum context length (1024).\n",
      "Number of tokens (1236) exceeded maximum context length (1024).\n",
      "Number of tokens (1237) exceeded maximum context length (1024).\n",
      "Number of tokens (1238) exceeded maximum context length (1024).\n",
      "Number of tokens (1239) exceeded maximum context length (1024).\n",
      "Number of tokens (1240) exceeded maximum context length (1024).\n",
      "Number of tokens (1241) exceeded maximum context length (1024).\n",
      "Number of tokens (1242) exceeded maximum context length (1024).\n",
      "Number of tokens (1243) exceeded maximum context length (1024).\n",
      "Number of tokens (1244) exceeded maximum context length (1024).\n",
      "Number of tokens (1245) exceeded maximum context length (1024).\n",
      "Number of tokens (1246) exceeded maximum context length (1024).\n",
      "Number of tokens (1247) exceeded maximum context length (1024).\n",
      "Number of tokens (1248) exceeded maximum context length (1024).\n",
      "Number of tokens (1249) exceeded maximum context length (1024).\n",
      "Number of tokens (1250) exceeded maximum context length (1024).\n",
      "Number of tokens (1251) exceeded maximum context length (1024).\n",
      "Number of tokens (1252) exceeded maximum context length (1024).\n",
      "Number of tokens (1253) exceeded maximum context length (1024).\n",
      "Number of tokens (1254) exceeded maximum context length (1024).\n",
      "Number of tokens (1255) exceeded maximum context length (1024).\n",
      "Number of tokens (1256) exceeded maximum context length (1024).\n",
      "Number of tokens (1257) exceeded maximum context length (1024).\n",
      "Number of tokens (1258) exceeded maximum context length (1024).\n",
      "Number of tokens (1259) exceeded maximum context length (1024).\n",
      "Number of tokens (1260) exceeded maximum context length (1024).\n",
      "Number of tokens (1261) exceeded maximum context length (1024).\n",
      "Number of tokens (1262) exceeded maximum context length (1024).\n",
      "Number of tokens (1263) exceeded maximum context length (1024).\n",
      "Number of tokens (1264) exceeded maximum context length (1024).\n",
      "Number of tokens (1265) exceeded maximum context length (1024).\n",
      "Number of tokens (1266) exceeded maximum context length (1024).\n",
      "Number of tokens (1267) exceeded maximum context length (1024).\n",
      "Number of tokens (1268) exceeded maximum context length (1024).\n",
      "Number of tokens (1269) exceeded maximum context length (1024).\n",
      "Number of tokens (1270) exceeded maximum context length (1024).\n",
      "Number of tokens (1271) exceeded maximum context length (1024).\n",
      "Number of tokens (1272) exceeded maximum context length (1024).\n",
      "Number of tokens (1273) exceeded maximum context length (1024).\n",
      "Number of tokens (1274) exceeded maximum context length (1024).\n",
      "Number of tokens (1275) exceeded maximum context length (1024).\n",
      "Number of tokens (1276) exceeded maximum context length (1024).\n",
      "Number of tokens (1277) exceeded maximum context length (1024).\n",
      "Number of tokens (1278) exceeded maximum context length (1024).\n",
      "Number of tokens (1279) exceeded maximum context length (1024).\n",
      "Number of tokens (1280) exceeded maximum context length (1024).\n",
      "Number of tokens (1281) exceeded maximum context length (1024).\n",
      "Number of tokens (1282) exceeded maximum context length (1024).\n",
      "Number of tokens (1283) exceeded maximum context length (1024).\n",
      "Number of tokens (1284) exceeded maximum context length (1024).\n",
      "Number of tokens (1285) exceeded maximum context length (1024).\n",
      "Number of tokens (1286) exceeded maximum context length (1024).\n",
      "Number of tokens (1287) exceeded maximum context length (1024).\n",
      "Number of tokens (1288) exceeded maximum context length (1024).\n",
      "Number of tokens (1289) exceeded maximum context length (1024).\n",
      "Number of tokens (1290) exceeded maximum context length (1024).\n",
      "Number of tokens (1291) exceeded maximum context length (1024).\n",
      "Number of tokens (1292) exceeded maximum context length (1024).\n",
      "Number of tokens (1293) exceeded maximum context length (1024).\n",
      "Number of tokens (1294) exceeded maximum context length (1024).\n",
      "Number of tokens (1295) exceeded maximum context length (1024).\n",
      "Number of tokens (1296) exceeded maximum context length (1024).\n",
      "Number of tokens (1297) exceeded maximum context length (1024).\n",
      "Number of tokens (1298) exceeded maximum context length (1024).\n",
      "Number of tokens (1299) exceeded maximum context length (1024).\n",
      "Number of tokens (1300) exceeded maximum context length (1024).\n",
      "Number of tokens (1301) exceeded maximum context length (1024).\n",
      "Number of tokens (1302) exceeded maximum context length (1024).\n",
      "Number of tokens (1303) exceeded maximum context length (1024).\n",
      "Number of tokens (1304) exceeded maximum context length (1024).\n",
      "Number of tokens (1305) exceeded maximum context length (1024).\n",
      "Number of tokens (1306) exceeded maximum context length (1024).\n",
      "Number of tokens (1307) exceeded maximum context length (1024).\n",
      "Number of tokens (1308) exceeded maximum context length (1024).\n",
      "Number of tokens (1309) exceeded maximum context length (1024).\n",
      "Number of tokens (1310) exceeded maximum context length (1024).\n",
      "Number of tokens (1311) exceeded maximum context length (1024).\n",
      "Number of tokens (1312) exceeded maximum context length (1024).\n",
      "Number of tokens (1313) exceeded maximum context length (1024).\n",
      "Number of tokens (1314) exceeded maximum context length (1024).\n",
      "Number of tokens (1315) exceeded maximum context length (1024).\n",
      "Number of tokens (1316) exceeded maximum context length (1024).\n",
      "Number of tokens (1317) exceeded maximum context length (1024).\n",
      "Number of tokens (1318) exceeded maximum context length (1024).\n",
      "Number of tokens (1319) exceeded maximum context length (1024).\n",
      "Number of tokens (1320) exceeded maximum context length (1024).\n",
      "Number of tokens (1321) exceeded maximum context length (1024).\n",
      "Number of tokens (1322) exceeded maximum context length (1024).\n",
      "Number of tokens (1323) exceeded maximum context length (1024).\n",
      "Number of tokens (1324) exceeded maximum context length (1024).\n",
      "Number of tokens (1325) exceeded maximum context length (1024).\n",
      "Number of tokens (1326) exceeded maximum context length (1024).\n",
      "Number of tokens (1327) exceeded maximum context length (1024).\n",
      "Number of tokens (1328) exceeded maximum context length (1024).\n",
      "Number of tokens (1329) exceeded maximum context length (1024).\n",
      "Number of tokens (1330) exceeded maximum context length (1024).\n",
      "Number of tokens (1331) exceeded maximum context length (1024).\n",
      "Number of tokens (1332) exceeded maximum context length (1024).\n",
      "Number of tokens (1333) exceeded maximum context length (1024).\n",
      "Number of tokens (1334) exceeded maximum context length (1024).\n",
      "Number of tokens (1335) exceeded maximum context length (1024).\n",
      "Number of tokens (1336) exceeded maximum context length (1024).\n",
      "Number of tokens (1337) exceeded maximum context length (1024).\n",
      "Number of tokens (1338) exceeded maximum context length (1024).\n",
      "Number of tokens (1339) exceeded maximum context length (1024).\n",
      "Number of tokens (1340) exceeded maximum context length (1024).\n",
      "Number of tokens (1341) exceeded maximum context length (1024).\n",
      "Number of tokens (1342) exceeded maximum context length (1024).\n",
      "Number of tokens (1343) exceeded maximum context length (1024).\n",
      "Number of tokens (1344) exceeded maximum context length (1024).\n",
      "Number of tokens (1345) exceeded maximum context length (1024).\n",
      "Number of tokens (1346) exceeded maximum context length (1024).\n",
      "Number of tokens (1347) exceeded maximum context length (1024).\n",
      "Number of tokens (1348) exceeded maximum context length (1024).\n",
      "Number of tokens (1349) exceeded maximum context length (1024).\n",
      "Number of tokens (1350) exceeded maximum context length (1024).\n",
      "Number of tokens (1351) exceeded maximum context length (1024).\n",
      "Number of tokens (1352) exceeded maximum context length (1024).\n",
      "Number of tokens (1353) exceeded maximum context length (1024).\n",
      "Number of tokens (1354) exceeded maximum context length (1024).\n",
      "Number of tokens (1355) exceeded maximum context length (1024).\n",
      "Number of tokens (1356) exceeded maximum context length (1024).\n",
      "Number of tokens (1357) exceeded maximum context length (1024).\n",
      "Number of tokens (1358) exceeded maximum context length (1024).\n",
      "Number of tokens (1359) exceeded maximum context length (1024).\n",
      "Number of tokens (1360) exceeded maximum context length (1024).\n",
      "Number of tokens (1361) exceeded maximum context length (1024).\n",
      "Number of tokens (1362) exceeded maximum context length (1024).\n",
      "Number of tokens (1363) exceeded maximum context length (1024).\n",
      "Number of tokens (1364) exceeded maximum context length (1024).\n",
      "Number of tokens (1365) exceeded maximum context length (1024).\n",
      "Number of tokens (1366) exceeded maximum context length (1024).\n",
      "Number of tokens (1367) exceeded maximum context length (1024).\n",
      "Number of tokens (1368) exceeded maximum context length (1024).\n",
      "Number of tokens (1369) exceeded maximum context length (1024).\n",
      "Number of tokens (1370) exceeded maximum context length (1024).\n",
      "Number of tokens (1371) exceeded maximum context length (1024).\n",
      "Number of tokens (1372) exceeded maximum context length (1024).\n",
      "Number of tokens (1373) exceeded maximum context length (1024).\n",
      "Number of tokens (1374) exceeded maximum context length (1024).\n",
      "Number of tokens (1375) exceeded maximum context length (1024).\n",
      "Number of tokens (1376) exceeded maximum context length (1024).\n",
      "Number of tokens (1377) exceeded maximum context length (1024).\n",
      "Number of tokens (1378) exceeded maximum context length (1024).\n",
      "Number of tokens (1379) exceeded maximum context length (1024).\n",
      "Number of tokens (1380) exceeded maximum context length (1024).\n",
      "Number of tokens (1381) exceeded maximum context length (1024).\n",
      "Number of tokens (1382) exceeded maximum context length (1024).\n",
      "Number of tokens (1383) exceeded maximum context length (1024).\n",
      "Number of tokens (1384) exceeded maximum context length (1024).\n",
      "Number of tokens (1385) exceeded maximum context length (1024).\n",
      "Number of tokens (1386) exceeded maximum context length (1024).\n",
      "Number of tokens (1387) exceeded maximum context length (1024).\n",
      "Number of tokens (1388) exceeded maximum context length (1024).\n",
      "Number of tokens (1389) exceeded maximum context length (1024).\n",
      "Number of tokens (1390) exceeded maximum context length (1024).\n",
      "Number of tokens (1391) exceeded maximum context length (1024).\n",
      "Number of tokens (1392) exceeded maximum context length (1024).\n",
      "Number of tokens (1393) exceeded maximum context length (1024).\n",
      "Number of tokens (1394) exceeded maximum context length (1024).\n",
      "Number of tokens (1395) exceeded maximum context length (1024).\n",
      "Number of tokens (1396) exceeded maximum context length (1024).\n",
      "Number of tokens (1397) exceeded maximum context length (1024).\n",
      "Number of tokens (1398) exceeded maximum context length (1024).\n",
      "Number of tokens (1399) exceeded maximum context length (1024).\n",
      "Number of tokens (1400) exceeded maximum context length (1024).\n",
      "Number of tokens (1401) exceeded maximum context length (1024).\n",
      "Number of tokens (1402) exceeded maximum context length (1024).\n",
      "Number of tokens (1403) exceeded maximum context length (1024).\n",
      "Number of tokens (1404) exceeded maximum context length (1024).\n",
      "Number of tokens (1405) exceeded maximum context length (1024).\n",
      "Number of tokens (1406) exceeded maximum context length (1024).\n",
      "Number of tokens (1407) exceeded maximum context length (1024).\n",
      "Number of tokens (1408) exceeded maximum context length (1024).\n",
      "Number of tokens (1409) exceeded maximum context length (1024).\n",
      "Number of tokens (1410) exceeded maximum context length (1024).\n",
      "Number of tokens (1411) exceeded maximum context length (1024).\n",
      "Number of tokens (1412) exceeded maximum context length (1024).\n",
      "Number of tokens (1413) exceeded maximum context length (1024).\n",
      "Number of tokens (1414) exceeded maximum context length (1024).\n",
      "Number of tokens (1415) exceeded maximum context length (1024).\n",
      "Number of tokens (1416) exceeded maximum context length (1024).\n",
      "Number of tokens (1417) exceeded maximum context length (1024).\n",
      "Number of tokens (1418) exceeded maximum context length (1024).\n",
      "Number of tokens (1419) exceeded maximum context length (1024).\n",
      "Number of tokens (1420) exceeded maximum context length (1024).\n",
      "Number of tokens (1421) exceeded maximum context length (1024).\n",
      "Number of tokens (1422) exceeded maximum context length (1024).\n",
      "Number of tokens (1423) exceeded maximum context length (1024).\n",
      "Number of tokens (1424) exceeded maximum context length (1024).\n",
      "Number of tokens (1425) exceeded maximum context length (1024).\n",
      "Number of tokens (1426) exceeded maximum context length (1024).\n",
      "Number of tokens (1427) exceeded maximum context length (1024).\n",
      "Number of tokens (1428) exceeded maximum context length (1024).\n",
      "Number of tokens (1429) exceeded maximum context length (1024).\n",
      "Number of tokens (1430) exceeded maximum context length (1024).\n",
      "Number of tokens (1431) exceeded maximum context length (1024).\n",
      "Number of tokens (1432) exceeded maximum context length (1024).\n",
      "Number of tokens (1433) exceeded maximum context length (1024).\n",
      "Number of tokens (1434) exceeded maximum context length (1024).\n",
      "Number of tokens (1435) exceeded maximum context length (1024).\n",
      "Number of tokens (1436) exceeded maximum context length (1024).\n",
      "Number of tokens (1437) exceeded maximum context length (1024).\n",
      "Number of tokens (1438) exceeded maximum context length (1024).\n",
      "Number of tokens (1439) exceeded maximum context length (1024).\n",
      "Number of tokens (1440) exceeded maximum context length (1024).\n",
      "Number of tokens (1441) exceeded maximum context length (1024).\n",
      "Number of tokens (1442) exceeded maximum context length (1024).\n",
      "Number of tokens (1443) exceeded maximum context length (1024).\n",
      "Number of tokens (1444) exceeded maximum context length (1024).\n",
      "Number of tokens (1445) exceeded maximum context length (1024).\n",
      "Number of tokens (1446) exceeded maximum context length (1024).\n",
      "Number of tokens (1447) exceeded maximum context length (1024).\n",
      "Number of tokens (1448) exceeded maximum context length (1024).\n",
      "Number of tokens (1449) exceeded maximum context length (1024).\n",
      "Number of tokens (1450) exceeded maximum context length (1024).\n",
      "Number of tokens (1451) exceeded maximum context length (1024).\n",
      "Number of tokens (1452) exceeded maximum context length (1024).\n",
      "Number of tokens (1453) exceeded maximum context length (1024).\n",
      "Number of tokens (1454) exceeded maximum context length (1024).\n",
      "Number of tokens (1455) exceeded maximum context length (1024).\n",
      "Number of tokens (1456) exceeded maximum context length (1024).\n",
      "Number of tokens (1457) exceeded maximum context length (1024).\n",
      "Number of tokens (1458) exceeded maximum context length (1024).\n",
      "Number of tokens (1459) exceeded maximum context length (1024).\n",
      "Number of tokens (1460) exceeded maximum context length (1024).\n",
      "Number of tokens (1461) exceeded maximum context length (1024).\n",
      "Number of tokens (1462) exceeded maximum context length (1024).\n",
      "Number of tokens (1463) exceeded maximum context length (1024).\n",
      "Number of tokens (1464) exceeded maximum context length (1024).\n",
      "Number of tokens (1465) exceeded maximum context length (1024).\n",
      "Number of tokens (1466) exceeded maximum context length (1024).\n",
      "Number of tokens (1467) exceeded maximum context length (1024).\n",
      "Number of tokens (1468) exceeded maximum context length (1024).\n",
      "Number of tokens (1469) exceeded maximum context length (1024).\n",
      "Number of tokens (1470) exceeded maximum context length (1024).\n",
      "Number of tokens (1471) exceeded maximum context length (1024).\n",
      "Number of tokens (1472) exceeded maximum context length (1024).\n",
      "Number of tokens (1473) exceeded maximum context length (1024).\n",
      "Number of tokens (1474) exceeded maximum context length (1024).\n",
      "Number of tokens (1475) exceeded maximum context length (1024).\n",
      "Number of tokens (1476) exceeded maximum context length (1024).\n",
      "Number of tokens (1477) exceeded maximum context length (1024).\n",
      "Number of tokens (1478) exceeded maximum context length (1024).\n",
      "Number of tokens (1479) exceeded maximum context length (1024).\n",
      "Number of tokens (1480) exceeded maximum context length (1024).\n",
      "Number of tokens (1481) exceeded maximum context length (1024).\n",
      "Number of tokens (1482) exceeded maximum context length (1024).\n",
      "Number of tokens (1483) exceeded maximum context length (1024).\n",
      "Number of tokens (1484) exceeded maximum context length (1024).\n",
      "Number of tokens (1485) exceeded maximum context length (1024).\n",
      "Number of tokens (1486) exceeded maximum context length (1024).\n",
      "Number of tokens (1487) exceeded maximum context length (1024).\n",
      "Number of tokens (1488) exceeded maximum context length (1024).\n",
      "Number of tokens (1489) exceeded maximum context length (1024).\n",
      "Number of tokens (1490) exceeded maximum context length (1024).\n",
      "Number of tokens (1491) exceeded maximum context length (1024).\n",
      "Number of tokens (1492) exceeded maximum context length (1024).\n",
      "Number of tokens (1493) exceeded maximum context length (1024).\n",
      "Number of tokens (1494) exceeded maximum context length (1024).\n",
      "Number of tokens (1495) exceeded maximum context length (1024).\n",
      "Number of tokens (1496) exceeded maximum context length (1024).\n",
      "Number of tokens (1497) exceeded maximum context length (1024).\n",
      "Number of tokens (1498) exceeded maximum context length (1024).\n",
      "Number of tokens (1499) exceeded maximum context length (1024).\n",
      "Number of tokens (1500) exceeded maximum context length (1024).\n",
      "Number of tokens (1501) exceeded maximum context length (1024).\n",
      "Number of tokens (1502) exceeded maximum context length (1024).\n",
      "Number of tokens (1503) exceeded maximum context length (1024).\n",
      "Number of tokens (1504) exceeded maximum context length (1024).\n",
      "Number of tokens (1505) exceeded maximum context length (1024).\n",
      "Number of tokens (1506) exceeded maximum context length (1024).\n",
      "Number of tokens (1507) exceeded maximum context length (1024).\n",
      "Number of tokens (1508) exceeded maximum context length (1024).\n",
      "Number of tokens (1509) exceeded maximum context length (1024).\n",
      "Number of tokens (1510) exceeded maximum context length (1024).\n",
      "Number of tokens (1511) exceeded maximum context length (1024).\n",
      "Number of tokens (1512) exceeded maximum context length (1024).\n",
      "Number of tokens (1513) exceeded maximum context length (1024).\n",
      "Number of tokens (1514) exceeded maximum context length (1024).\n",
      "Number of tokens (1515) exceeded maximum context length (1024).\n",
      "Number of tokens (1516) exceeded maximum context length (1024).\n",
      "Number of tokens (1517) exceeded maximum context length (1024).\n",
      "Number of tokens (1518) exceeded maximum context length (1024).\n",
      "Number of tokens (1519) exceeded maximum context length (1024).\n",
      "Number of tokens (1520) exceeded maximum context length (1024).\n",
      "Number of tokens (1521) exceeded maximum context length (1024).\n",
      "Number of tokens (1522) exceeded maximum context length (1024).\n",
      "Number of tokens (1523) exceeded maximum context length (1024).\n",
      "Number of tokens (1524) exceeded maximum context length (1024).\n",
      "Number of tokens (1525) exceeded maximum context length (1024).\n",
      "Number of tokens (1526) exceeded maximum context length (1024).\n",
      "Number of tokens (1527) exceeded maximum context length (1024).\n",
      "Number of tokens (1528) exceeded maximum context length (1024).\n",
      "Number of tokens (1529) exceeded maximum context length (1024).\n",
      "Number of tokens (1530) exceeded maximum context length (1024).\n",
      "Number of tokens (1531) exceeded maximum context length (1024).\n",
      "Number of tokens (1532) exceeded maximum context length (1024).\n",
      "Number of tokens (1533) exceeded maximum context length (1024).\n",
      "Number of tokens (1534) exceeded maximum context length (1024).\n",
      "Number of tokens (1535) exceeded maximum context length (1024).\n",
      "Number of tokens (1536) exceeded maximum context length (1024).\n",
      "Number of tokens (1537) exceeded maximum context length (1024).\n",
      "Number of tokens (1538) exceeded maximum context length (1024).\n",
      "Number of tokens (1539) exceeded maximum context length (1024).\n",
      "Number of tokens (1540) exceeded maximum context length (1024).\n",
      "Number of tokens (1541) exceeded maximum context length (1024).\n",
      "Number of tokens (1542) exceeded maximum context length (1024).\n",
      "Number of tokens (1543) exceeded maximum context length (1024).\n",
      "Number of tokens (1544) exceeded maximum context length (1024).\n",
      "Number of tokens (1545) exceeded maximum context length (1024).\n",
      "Number of tokens (1546) exceeded maximum context length (1024).\n",
      "Number of tokens (1547) exceeded maximum context length (1024).\n",
      "Number of tokens (1548) exceeded maximum context length (1024).\n",
      "Number of tokens (1549) exceeded maximum context length (1024).\n",
      "Number of tokens (1550) exceeded maximum context length (1024).\n",
      "Number of tokens (1551) exceeded maximum context length (1024).\n",
      "Number of tokens (1552) exceeded maximum context length (1024).\n",
      "Number of tokens (1553) exceeded maximum context length (1024).\n",
      "Number of tokens (1554) exceeded maximum context length (1024).\n",
      "Number of tokens (1555) exceeded maximum context length (1024).\n",
      "Number of tokens (1556) exceeded maximum context length (1024).\n",
      "Number of tokens (1557) exceeded maximum context length (1024).\n",
      "Number of tokens (1558) exceeded maximum context length (1024).\n",
      "Number of tokens (1559) exceeded maximum context length (1024).\n",
      "Number of tokens (1560) exceeded maximum context length (1024).\n",
      "Number of tokens (1561) exceeded maximum context length (1024).\n",
      "Number of tokens (1562) exceeded maximum context length (1024).\n",
      "Number of tokens (1563) exceeded maximum context length (1024).\n",
      "Number of tokens (1564) exceeded maximum context length (1024).\n",
      "Number of tokens (1565) exceeded maximum context length (1024).\n",
      "Number of tokens (1566) exceeded maximum context length (1024).\n",
      "Number of tokens (1567) exceeded maximum context length (1024).\n",
      "Number of tokens (1568) exceeded maximum context length (1024).\n",
      "Number of tokens (1569) exceeded maximum context length (1024).\n",
      "Number of tokens (1570) exceeded maximum context length (1024).\n",
      "Number of tokens (1571) exceeded maximum context length (1024).\n",
      "Number of tokens (1572) exceeded maximum context length (1024).\n",
      "Number of tokens (1573) exceeded maximum context length (1024).\n",
      "Number of tokens (1574) exceeded maximum context length (1024).\n",
      "Number of tokens (1575) exceeded maximum context length (1024).\n",
      "Number of tokens (1576) exceeded maximum context length (1024).\n",
      "Number of tokens (1577) exceeded maximum context length (1024).\n",
      "Number of tokens (1578) exceeded maximum context length (1024).\n",
      "Number of tokens (1579) exceeded maximum context length (1024).\n",
      "Number of tokens (1580) exceeded maximum context length (1024).\n",
      "Number of tokens (1581) exceeded maximum context length (1024).\n",
      "Number of tokens (1582) exceeded maximum context length (1024).\n",
      "Number of tokens (1583) exceeded maximum context length (1024).\n",
      "Number of tokens (1584) exceeded maximum context length (1024).\n",
      "Number of tokens (1585) exceeded maximum context length (1024).\n",
      "Number of tokens (1586) exceeded maximum context length (1024).\n",
      "Number of tokens (1587) exceeded maximum context length (1024).\n",
      "Number of tokens (1588) exceeded maximum context length (1024).\n",
      "Number of tokens (1589) exceeded maximum context length (1024).\n",
      "Number of tokens (1590) exceeded maximum context length (1024).\n",
      "Number of tokens (1591) exceeded maximum context length (1024).\n",
      "Number of tokens (1592) exceeded maximum context length (1024).\n",
      "Number of tokens (1593) exceeded maximum context length (1024).\n",
      "Number of tokens (1594) exceeded maximum context length (1024).\n",
      "Number of tokens (1595) exceeded maximum context length (1024).\n",
      "Number of tokens (1596) exceeded maximum context length (1024).\n",
      "Number of tokens (1597) exceeded maximum context length (1024).\n",
      "Number of tokens (1598) exceeded maximum context length (1024).\n",
      "Number of tokens (1599) exceeded maximum context length (1024).\n",
      "Number of tokens (1600) exceeded maximum context length (1024).\n",
      "Number of tokens (1601) exceeded maximum context length (1024).\n",
      "Number of tokens (1602) exceeded maximum context length (1024).\n",
      "Number of tokens (1603) exceeded maximum context length (1024).\n",
      "Number of tokens (1604) exceeded maximum context length (1024).\n",
      "Number of tokens (1605) exceeded maximum context length (1024).\n",
      "Number of tokens (1606) exceeded maximum context length (1024).\n",
      "Number of tokens (1607) exceeded maximum context length (1024).\n",
      "Number of tokens (1608) exceeded maximum context length (1024).\n",
      "Number of tokens (1609) exceeded maximum context length (1024).\n",
      "Number of tokens (1610) exceeded maximum context length (1024).\n",
      "Number of tokens (1611) exceeded maximum context length (1024).\n",
      "Number of tokens (1612) exceeded maximum context length (1024).\n",
      "Number of tokens (1613) exceeded maximum context length (1024).\n",
      "Number of tokens (1614) exceeded maximum context length (1024).\n",
      "Number of tokens (1615) exceeded maximum context length (1024).\n",
      "Number of tokens (1616) exceeded maximum context length (1024).\n",
      "Number of tokens (1617) exceeded maximum context length (1024).\n",
      "Number of tokens (1618) exceeded maximum context length (1024).\n",
      "Number of tokens (1619) exceeded maximum context length (1024).\n",
      "Number of tokens (1620) exceeded maximum context length (1024).\n",
      "Number of tokens (1621) exceeded maximum context length (1024).\n",
      "Number of tokens (1622) exceeded maximum context length (1024).\n",
      "Number of tokens (1623) exceeded maximum context length (1024).\n",
      "Number of tokens (1624) exceeded maximum context length (1024).\n",
      "Number of tokens (1625) exceeded maximum context length (1024).\n",
      "Number of tokens (1626) exceeded maximum context length (1024).\n",
      "Number of tokens (1627) exceeded maximum context length (1024).\n",
      "Number of tokens (1628) exceeded maximum context length (1024).\n",
      "Number of tokens (1629) exceeded maximum context length (1024).\n",
      "Number of tokens (1630) exceeded maximum context length (1024).\n",
      "Number of tokens (1631) exceeded maximum context length (1024).\n",
      "Number of tokens (1632) exceeded maximum context length (1024).\n",
      "Number of tokens (1633) exceeded maximum context length (1024).\n",
      "Number of tokens (1634) exceeded maximum context length (1024).\n",
      "Number of tokens (1635) exceeded maximum context length (1024).\n",
      "Number of tokens (1636) exceeded maximum context length (1024).\n",
      "Number of tokens (1637) exceeded maximum context length (1024).\n",
      "Number of tokens (1638) exceeded maximum context length (1024).\n",
      "Number of tokens (1639) exceeded maximum context length (1024).\n",
      "Number of tokens (1640) exceeded maximum context length (1024).\n",
      "Number of tokens (1641) exceeded maximum context length (1024).\n",
      "Number of tokens (1642) exceeded maximum context length (1024).\n",
      "Number of tokens (1643) exceeded maximum context length (1024).\n",
      "Number of tokens (1644) exceeded maximum context length (1024).\n",
      "Number of tokens (1645) exceeded maximum context length (1024).\n",
      "Number of tokens (1646) exceeded maximum context length (1024).\n",
      "Number of tokens (1647) exceeded maximum context length (1024).\n",
      "Number of tokens (1648) exceeded maximum context length (1024).\n",
      "Number of tokens (1649) exceeded maximum context length (1024).\n",
      "Number of tokens (1650) exceeded maximum context length (1024).\n",
      "Number of tokens (1651) exceeded maximum context length (1024).\n",
      "Number of tokens (1652) exceeded maximum context length (1024).\n",
      "Number of tokens (1653) exceeded maximum context length (1024).\n",
      "Number of tokens (1654) exceeded maximum context length (1024).\n",
      "Number of tokens (1655) exceeded maximum context length (1024).\n",
      "Number of tokens (1656) exceeded maximum context length (1024).\n",
      "Number of tokens (1657) exceeded maximum context length (1024).\n",
      "Number of tokens (1658) exceeded maximum context length (1024).\n",
      "Number of tokens (1659) exceeded maximum context length (1024).\n",
      "Number of tokens (1660) exceeded maximum context length (1024).\n",
      "Number of tokens (1661) exceeded maximum context length (1024).\n",
      "Number of tokens (1662) exceeded maximum context length (1024).\n",
      "Number of tokens (1663) exceeded maximum context length (1024).\n",
      "Number of tokens (1664) exceeded maximum context length (1024).\n",
      "Number of tokens (1665) exceeded maximum context length (1024).\n",
      "Number of tokens (1666) exceeded maximum context length (1024).\n",
      "Number of tokens (1667) exceeded maximum context length (1024).\n",
      "Number of tokens (1668) exceeded maximum context length (1024).\n",
      "Number of tokens (1669) exceeded maximum context length (1024).\n",
      "Number of tokens (1670) exceeded maximum context length (1024).\n",
      "Number of tokens (1671) exceeded maximum context length (1024).\n",
      "Number of tokens (1672) exceeded maximum context length (1024).\n",
      "Number of tokens (1673) exceeded maximum context length (1024).\n",
      "Number of tokens (1674) exceeded maximum context length (1024).\n",
      "Number of tokens (1675) exceeded maximum context length (1024).\n",
      "Number of tokens (1676) exceeded maximum context length (1024).\n",
      "Number of tokens (1677) exceeded maximum context length (1024).\n",
      "Number of tokens (1678) exceeded maximum context length (1024).\n",
      "Number of tokens (1679) exceeded maximum context length (1024).\n",
      "Number of tokens (1680) exceeded maximum context length (1024).\n",
      "Number of tokens (1681) exceeded maximum context length (1024).\n",
      "Number of tokens (1682) exceeded maximum context length (1024).\n",
      "Number of tokens (1683) exceeded maximum context length (1024).\n",
      "Number of tokens (1684) exceeded maximum context length (1024).\n",
      "Number of tokens (1685) exceeded maximum context length (1024).\n",
      "Number of tokens (1686) exceeded maximum context length (1024).\n",
      "Number of tokens (1687) exceeded maximum context length (1024).\n",
      "Number of tokens (1688) exceeded maximum context length (1024).\n",
      "Number of tokens (1689) exceeded maximum context length (1024).\n",
      "Number of tokens (1690) exceeded maximum context length (1024).\n",
      "Number of tokens (1691) exceeded maximum context length (1024).\n",
      "Number of tokens (1692) exceeded maximum context length (1024).\n",
      "Number of tokens (1693) exceeded maximum context length (1024).\n",
      "Number of tokens (1694) exceeded maximum context length (1024).\n",
      "Number of tokens (1695) exceeded maximum context length (1024).\n",
      "Number of tokens (1696) exceeded maximum context length (1024).\n",
      "Number of tokens (1697) exceeded maximum context length (1024).\n",
      "Number of tokens (1698) exceeded maximum context length (1024).\n",
      "Number of tokens (1699) exceeded maximum context length (1024).\n",
      "Number of tokens (1700) exceeded maximum context length (1024).\n",
      "Number of tokens (1701) exceeded maximum context length (1024).\n",
      "Number of tokens (1702) exceeded maximum context length (1024).\n",
      "Number of tokens (1703) exceeded maximum context length (1024).\n",
      "Number of tokens (1704) exceeded maximum context length (1024).\n",
      "Number of tokens (1705) exceeded maximum context length (1024).\n",
      "Number of tokens (1706) exceeded maximum context length (1024).\n",
      "Number of tokens (1707) exceeded maximum context length (1024).\n",
      "Number of tokens (1708) exceeded maximum context length (1024).\n",
      "Number of tokens (1709) exceeded maximum context length (1024).\n",
      "Number of tokens (1710) exceeded maximum context length (1024).\n",
      "Number of tokens (1711) exceeded maximum context length (1024).\n",
      "Number of tokens (1712) exceeded maximum context length (1024).\n",
      "Number of tokens (1713) exceeded maximum context length (1024).\n",
      "Number of tokens (1714) exceeded maximum context length (1024).\n",
      "Number of tokens (1715) exceeded maximum context length (1024).\n",
      "Number of tokens (1716) exceeded maximum context length (1024).\n",
      "Number of tokens (1717) exceeded maximum context length (1024).\n",
      "Number of tokens (1718) exceeded maximum context length (1024).\n",
      "Number of tokens (1719) exceeded maximum context length (1024).\n",
      "Number of tokens (1720) exceeded maximum context length (1024).\n",
      "Number of tokens (1721) exceeded maximum context length (1024).\n",
      "Number of tokens (1722) exceeded maximum context length (1024).\n",
      "Number of tokens (1723) exceeded maximum context length (1024).\n",
      "Number of tokens (1724) exceeded maximum context length (1024).\n",
      "Number of tokens (1725) exceeded maximum context length (1024).\n",
      "Number of tokens (1726) exceeded maximum context length (1024).\n",
      "Number of tokens (1727) exceeded maximum context length (1024).\n",
      "Number of tokens (1728) exceeded maximum context length (1024).\n",
      "Number of tokens (1729) exceeded maximum context length (1024).\n",
      "Number of tokens (1730) exceeded maximum context length (1024).\n",
      "Number of tokens (1731) exceeded maximum context length (1024).\n",
      "Number of tokens (1732) exceeded maximum context length (1024).\n",
      "Number of tokens (1733) exceeded maximum context length (1024).\n",
      "Number of tokens (1734) exceeded maximum context length (1024).\n",
      "Number of tokens (1735) exceeded maximum context length (1024).\n",
      "Number of tokens (1736) exceeded maximum context length (1024).\n",
      "Number of tokens (1737) exceeded maximum context length (1024).\n",
      "Number of tokens (1738) exceeded maximum context length (1024).\n",
      "Number of tokens (1739) exceeded maximum context length (1024).\n",
      "Number of tokens (1740) exceeded maximum context length (1024).\n",
      "Number of tokens (1741) exceeded maximum context length (1024).\n",
      "Number of tokens (1742) exceeded maximum context length (1024).\n",
      "Number of tokens (1743) exceeded maximum context length (1024).\n",
      "Number of tokens (1744) exceeded maximum context length (1024).\n",
      "Number of tokens (1745) exceeded maximum context length (1024).\n",
      "Number of tokens (1746) exceeded maximum context length (1024).\n",
      "Number of tokens (1747) exceeded maximum context length (1024).\n",
      "Number of tokens (1748) exceeded maximum context length (1024).\n",
      "Number of tokens (1749) exceeded maximum context length (1024).\n",
      "Number of tokens (1750) exceeded maximum context length (1024).\n",
      "Number of tokens (1751) exceeded maximum context length (1024).\n",
      "Number of tokens (1752) exceeded maximum context length (1024).\n",
      "Number of tokens (1753) exceeded maximum context length (1024).\n",
      "Number of tokens (1754) exceeded maximum context length (1024).\n",
      "Number of tokens (1755) exceeded maximum context length (1024).\n",
      "Number of tokens (1756) exceeded maximum context length (1024).\n",
      "Number of tokens (1757) exceeded maximum context length (1024).\n",
      "Number of tokens (1758) exceeded maximum context length (1024).\n",
      "Number of tokens (1759) exceeded maximum context length (1024).\n",
      "Number of tokens (1760) exceeded maximum context length (1024).\n",
      "Number of tokens (1761) exceeded maximum context length (1024).\n",
      "Number of tokens (1762) exceeded maximum context length (1024).\n",
      "Number of tokens (1763) exceeded maximum context length (1024).\n",
      "Number of tokens (1764) exceeded maximum context length (1024).\n",
      "Number of tokens (1765) exceeded maximum context length (1024).\n",
      "Number of tokens (1766) exceeded maximum context length (1024).\n",
      "Number of tokens (1767) exceeded maximum context length (1024).\n",
      "Number of tokens (1768) exceeded maximum context length (1024).\n",
      "Number of tokens (1769) exceeded maximum context length (1024).\n",
      "Number of tokens (1770) exceeded maximum context length (1024).\n",
      "Number of tokens (1771) exceeded maximum context length (1024).\n",
      "Number of tokens (1772) exceeded maximum context length (1024).\n",
      "Number of tokens (1773) exceeded maximum context length (1024).\n",
      "Number of tokens (1774) exceeded maximum context length (1024).\n",
      "Number of tokens (1775) exceeded maximum context length (1024).\n",
      "Number of tokens (1776) exceeded maximum context length (1024).\n",
      "Number of tokens (1777) exceeded maximum context length (1024).\n",
      "Number of tokens (1778) exceeded maximum context length (1024).\n",
      "Number of tokens (1779) exceeded maximum context length (1024).\n",
      "Number of tokens (1780) exceeded maximum context length (1024).\n",
      "Number of tokens (1781) exceeded maximum context length (1024).\n",
      "Number of tokens (1782) exceeded maximum context length (1024).\n",
      "Number of tokens (1783) exceeded maximum context length (1024).\n",
      "Number of tokens (1784) exceeded maximum context length (1024).\n",
      "Number of tokens (1785) exceeded maximum context length (1024).\n",
      "Number of tokens (1786) exceeded maximum context length (1024).\n",
      "Number of tokens (1787) exceeded maximum context length (1024).\n",
      "Number of tokens (1788) exceeded maximum context length (1024).\n",
      "Number of tokens (1789) exceeded maximum context length (1024).\n",
      "Number of tokens (1790) exceeded maximum context length (1024).\n",
      "Number of tokens (1791) exceeded maximum context length (1024).\n",
      "Number of tokens (1792) exceeded maximum context length (1024).\n",
      "Number of tokens (1793) exceeded maximum context length (1024).\n",
      "Number of tokens (1794) exceeded maximum context length (1024).\n",
      "Number of tokens (1795) exceeded maximum context length (1024).\n",
      "Number of tokens (1796) exceeded maximum context length (1024).\n",
      "Number of tokens (1797) exceeded maximum context length (1024).\n",
      "Number of tokens (1798) exceeded maximum context length (1024).\n",
      "Number of tokens (1799) exceeded maximum context length (1024).\n",
      "Number of tokens (1800) exceeded maximum context length (1024).\n",
      "Number of tokens (1801) exceeded maximum context length (1024).\n",
      "Number of tokens (1802) exceeded maximum context length (1024).\n",
      "Number of tokens (1803) exceeded maximum context length (1024).\n",
      "Number of tokens (1804) exceeded maximum context length (1024).\n",
      "Number of tokens (1805) exceeded maximum context length (1024).\n",
      "Number of tokens (1806) exceeded maximum context length (1024).\n",
      "Number of tokens (1807) exceeded maximum context length (1024).\n",
      "Number of tokens (1808) exceeded maximum context length (1024).\n",
      "Number of tokens (1809) exceeded maximum context length (1024).\n",
      "Number of tokens (1810) exceeded maximum context length (1024).\n",
      "Number of tokens (1811) exceeded maximum context length (1024).\n",
      "Number of tokens (1812) exceeded maximum context length (1024).\n",
      "Number of tokens (1813) exceeded maximum context length (1024).\n",
      "Number of tokens (1814) exceeded maximum context length (1024).\n",
      "Number of tokens (1815) exceeded maximum context length (1024).\n",
      "Number of tokens (1816) exceeded maximum context length (1024).\n",
      "Number of tokens (1817) exceeded maximum context length (1024).\n",
      "Number of tokens (1818) exceeded maximum context length (1024).\n",
      "Number of tokens (1819) exceeded maximum context length (1024).\n",
      "Number of tokens (1820) exceeded maximum context length (1024).\n",
      "Number of tokens (1821) exceeded maximum context length (1024).\n",
      "Number of tokens (1822) exceeded maximum context length (1024).\n",
      "Number of tokens (1823) exceeded maximum context length (1024).\n",
      "Number of tokens (1824) exceeded maximum context length (1024).\n",
      "Number of tokens (1825) exceeded maximum context length (1024).\n",
      "Number of tokens (1826) exceeded maximum context length (1024).\n",
      "Number of tokens (1827) exceeded maximum context length (1024).\n",
      "Number of tokens (1828) exceeded maximum context length (1024).\n",
      "Number of tokens (1829) exceeded maximum context length (1024).\n",
      "Number of tokens (1830) exceeded maximum context length (1024).\n",
      "Number of tokens (1831) exceeded maximum context length (1024).\n",
      "Number of tokens (1832) exceeded maximum context length (1024).\n",
      "Number of tokens (1833) exceeded maximum context length (1024).\n",
      "Number of tokens (1834) exceeded maximum context length (1024).\n",
      "Number of tokens (1835) exceeded maximum context length (1024).\n",
      "Number of tokens (1836) exceeded maximum context length (1024).\n",
      "Number of tokens (1837) exceeded maximum context length (1024).\n",
      "Number of tokens (1838) exceeded maximum context length (1024).\n",
      "Number of tokens (1839) exceeded maximum context length (1024).\n",
      "Number of tokens (1840) exceeded maximum context length (1024).\n",
      "Number of tokens (1841) exceeded maximum context length (1024).\n",
      "Number of tokens (1842) exceeded maximum context length (1024).\n",
      "Number of tokens (1843) exceeded maximum context length (1024).\n",
      "Number of tokens (1844) exceeded maximum context length (1024).\n",
      "Number of tokens (1845) exceeded maximum context length (1024).\n",
      "Number of tokens (1846) exceeded maximum context length (1024).\n",
      "Number of tokens (1847) exceeded maximum context length (1024).\n",
      "Number of tokens (1848) exceeded maximum context length (1024).\n",
      "Number of tokens (1849) exceeded maximum context length (1024).\n",
      "Number of tokens (1850) exceeded maximum context length (1024).\n",
      "Number of tokens (1851) exceeded maximum context length (1024).\n",
      "Number of tokens (1852) exceeded maximum context length (1024).\n",
      "Number of tokens (1853) exceeded maximum context length (1024).\n",
      "Number of tokens (1854) exceeded maximum context length (1024).\n",
      "Number of tokens (1855) exceeded maximum context length (1024).\n",
      "Number of tokens (1856) exceeded maximum context length (1024).\n",
      "Number of tokens (1857) exceeded maximum context length (1024).\n",
      "Number of tokens (1858) exceeded maximum context length (1024).\n",
      "Number of tokens (1859) exceeded maximum context length (1024).\n",
      "Number of tokens (1860) exceeded maximum context length (1024).\n",
      "Number of tokens (1861) exceeded maximum context length (1024).\n",
      "Number of tokens (1862) exceeded maximum context length (1024).\n",
      "Number of tokens (1863) exceeded maximum context length (1024).\n",
      "Number of tokens (1864) exceeded maximum context length (1024).\n",
      "Number of tokens (1865) exceeded maximum context length (1024).\n",
      "Number of tokens (1866) exceeded maximum context length (1024).\n",
      "Number of tokens (1867) exceeded maximum context length (1024).\n",
      "Number of tokens (1868) exceeded maximum context length (1024).\n",
      "Number of tokens (1869) exceeded maximum context length (1024).\n",
      "Number of tokens (1870) exceeded maximum context length (1024).\n",
      "Number of tokens (1871) exceeded maximum context length (1024).\n",
      "Number of tokens (1872) exceeded maximum context length (1024).\n",
      "Number of tokens (1873) exceeded maximum context length (1024).\n",
      "Number of tokens (1874) exceeded maximum context length (1024).\n",
      "Number of tokens (1875) exceeded maximum context length (1024).\n",
      "Number of tokens (1876) exceeded maximum context length (1024).\n",
      "Number of tokens (1877) exceeded maximum context length (1024).\n",
      "Number of tokens (1878) exceeded maximum context length (1024).\n",
      "Number of tokens (1879) exceeded maximum context length (1024).\n",
      "Number of tokens (1880) exceeded maximum context length (1024).\n",
      "Number of tokens (1881) exceeded maximum context length (1024).\n",
      "Number of tokens (1882) exceeded maximum context length (1024).\n",
      "Number of tokens (1883) exceeded maximum context length (1024).\n",
      "Number of tokens (1884) exceeded maximum context length (1024).\n",
      "Number of tokens (1885) exceeded maximum context length (1024).\n",
      "Number of tokens (1886) exceeded maximum context length (1024).\n",
      "Number of tokens (1887) exceeded maximum context length (1024).\n",
      "Number of tokens (1888) exceeded maximum context length (1024).\n",
      "Number of tokens (1889) exceeded maximum context length (1024).\n",
      "Number of tokens (1890) exceeded maximum context length (1024).\n",
      "Number of tokens (1891) exceeded maximum context length (1024).\n",
      "Number of tokens (1892) exceeded maximum context length (1024).\n",
      "Number of tokens (1893) exceeded maximum context length (1024).\n",
      "Number of tokens (1894) exceeded maximum context length (1024).\n",
      "Number of tokens (1895) exceeded maximum context length (1024).\n",
      "Number of tokens (1896) exceeded maximum context length (1024).\n",
      "Number of tokens (1897) exceeded maximum context length (1024).\n",
      "Number of tokens (1898) exceeded maximum context length (1024).\n",
      "Number of tokens (1899) exceeded maximum context length (1024).\n",
      "Number of tokens (1900) exceeded maximum context length (1024).\n",
      "Number of tokens (1901) exceeded maximum context length (1024).\n",
      "Number of tokens (1902) exceeded maximum context length (1024).\n",
      "Number of tokens (1903) exceeded maximum context length (1024).\n",
      "Number of tokens (1904) exceeded maximum context length (1024).\n",
      "Number of tokens (1905) exceeded maximum context length (1024).\n",
      "Number of tokens (1906) exceeded maximum context length (1024).\n",
      "Number of tokens (1907) exceeded maximum context length (1024).\n",
      "Number of tokens (1908) exceeded maximum context length (1024).\n",
      "Number of tokens (1909) exceeded maximum context length (1024).\n",
      "Number of tokens (1910) exceeded maximum context length (1024).\n",
      "Number of tokens (1911) exceeded maximum context length (1024).\n",
      "Number of tokens (1912) exceeded maximum context length (1024).\n",
      "Number of tokens (1913) exceeded maximum context length (1024).\n",
      "Number of tokens (1914) exceeded maximum context length (1024).\n",
      "Number of tokens (1915) exceeded maximum context length (1024).\n",
      "Number of tokens (1916) exceeded maximum context length (1024).\n",
      "Number of tokens (1917) exceeded maximum context length (1024).\n",
      "Number of tokens (1918) exceeded maximum context length (1024).\n",
      "Number of tokens (1919) exceeded maximum context length (1024).\n",
      "Number of tokens (1920) exceeded maximum context length (1024).\n",
      "Number of tokens (1921) exceeded maximum context length (1024).\n",
      "Number of tokens (1922) exceeded maximum context length (1024).\n",
      "Number of tokens (1923) exceeded maximum context length (1024).\n",
      "Number of tokens (1924) exceeded maximum context length (1024).\n",
      "Number of tokens (1925) exceeded maximum context length (1024).\n",
      "Number of tokens (1926) exceeded maximum context length (1024).\n",
      "Number of tokens (1927) exceeded maximum context length (1024).\n",
      "Number of tokens (1928) exceeded maximum context length (1024).\n",
      "Number of tokens (1929) exceeded maximum context length (1024).\n",
      "Number of tokens (1930) exceeded maximum context length (1024).\n",
      "Number of tokens (1931) exceeded maximum context length (1024).\n",
      "Number of tokens (1932) exceeded maximum context length (1024).\n",
      "Number of tokens (1933) exceeded maximum context length (1024).\n",
      "Number of tokens (1934) exceeded maximum context length (1024).\n",
      "Number of tokens (1935) exceeded maximum context length (1024).\n",
      "Number of tokens (1936) exceeded maximum context length (1024).\n",
      "Number of tokens (1937) exceeded maximum context length (1024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aditya has several strengths as a candidate. He is a state topper in CBSE Class 10th exams and an NTSE\n",
      "Scholar, indicating his academic excellence. He has also received a prestigious fellowship from IBITF for his\n",
      "work on the Divyadrishti mobile application. In addition to his academic achievements, Aditya has experience\n",
      "working as a Project Assistant at Magnetica, Australia, where he was involved in R&D and C++ implementation of\n",
      "an algorithm to illuminate low signal regions of MRI regions of MRI regions of MRI regions of MRI regions of\n",
      "MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI\n",
      "regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of MRI regions of\n",
      "\n",
      "\n",
      "Sources:\n",
      "data/Resume_balanced.pdf\n",
      "data/Resume_balanced.pdf\n",
      "data/Resume_balanced.pdf\n",
      "CPU times: total: 41min\n",
      "Wall time: 25min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# example\n",
    "query = \"What are the strengths of candidate, Aditya?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4250809,
     "sourceId": 7324138,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
